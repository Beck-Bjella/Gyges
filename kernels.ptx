//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34841621
// Cuda compilation tools, release 12.6, V12.6.77
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_52
.address_size 64

	// .globl	unified_kernel
.const .align 8 .b8 ALL_INTERCEPTS[576] = {66, 0, 0, 0, 0, 0, 0, 0, 133, 0, 0, 0, 0, 0, 0, 0, 10, 1, 0, 0, 0, 0, 0, 0, 20, 2, 0, 0, 0, 0, 0, 0, 40, 4, 0, 0, 0, 0, 0, 0, 16, 8, 0, 0, 0, 0, 0, 0, 129, 16, 0, 0, 0, 0, 0, 0, 66, 33, 0, 0, 0, 0, 0, 0, 132, 66, 0, 0, 0, 0, 0, 0, 8, 133, 0, 0, 0, 0, 0, 0, 16, 10, 1, 0, 0, 0, 0, 0, 32, 4, 2, 0, 0, 0, 0, 0, 64, 32, 4, 0, 0, 0, 0, 0, 128, 80, 8, 0, 0, 0, 0, 0, 0, 161, 16, 0, 0, 0, 0, 0, 0, 66, 33, 0, 0, 0, 0, 0, 0, 132, 66, 0, 0, 0, 0, 0, 0, 8, 129, 0, 0, 0, 0, 0, 0, 16, 8, 1, 0, 0, 0, 0, 0, 32, 20, 2, 0, 0, 0, 0, 0, 64, 40, 4, 0, 0, 0, 0, 0, 128, 80, 8, 0, 0, 0, 0, 0, 0, 161, 16, 0, 0, 0, 0, 0, 0, 66, 32, 0, 0, 0, 0, 0, 0, 4, 66, 0, 0, 0, 0, 0, 0, 8, 133, 0, 0, 0, 0, 0, 0, 16, 10, 1, 0, 0, 0, 0, 0, 32, 20, 2, 0, 0, 0, 0, 0, 64, 40, 4, 0, 0, 0, 0, 0, 128, 16, 8, 0, 0, 0, 0, 0, 0, 129, 0, 0, 0, 0, 0, 0, 0, 66, 1, 0, 0, 0, 0, 0, 0, 132, 2, 0, 0, 0, 0, 0, 0, 8, 5, 0, 0, 0, 0, 0, 0, 16, 10, 0, 0, 0, 0, 0, 0, 32, 4, 0, 0, 0, 198, 16, 0, 0, 0, 0, 0, 0, 205, 33, 0, 0, 0, 0, 0, 0, 155, 67, 0, 0, 0, 0, 0, 0, 54, 135, 0, 0, 0, 0, 0, 0, 44, 14, 1, 0, 0, 0, 0, 0, 24, 12, 2, 0, 0, 0, 0, 0, 131, 49, 4, 0, 0, 0, 0, 0, 71, 115, 8, 0, 0, 0, 0, 0, 206, 230, 16, 0, 0, 0, 0, 0, 156, 205, 33, 0, 0, 0, 0, 0, 56, 139, 67, 0, 0, 0, 0, 0, 48, 6, 131, 0, 0, 0, 0, 0, 193, 96, 12, 1, 0, 0, 0, 0, 194, 209, 28, 2, 0, 0, 0, 0, 132, 179, 57, 4, 0, 0, 0, 0, 8, 103, 115, 8, 0, 0, 0, 0, 16, 206, 226, 16, 0, 0, 0, 0, 32, 140, 193, 32, 0, 0, 0, 0, 64, 48, 24, 67, 0, 0, 0, 0, 128, 112, 52, 135, 0, 0, 0, 0, 0, 225, 108, 14, 1, 0, 0, 0, 0, 194, 217, 28, 2, 0, 0, 0, 0, 132, 179, 56, 4, 0, 0, 0, 0, 8, 99, 48, 8, 0, 0, 0, 0, 16, 12, 198, 0, 0, 0, 0, 0, 32, 28, 205, 1, 0, 0, 0, 0, 64, 56, 155, 3, 0, 0, 0, 0, 128, 112, 54, 7, 0, 0, 0, 0, 0, 225, 44, 14, 0, 0, 0, 0, 0, 194, 24, 12, 0, 0, 0, 0, 0, 4, 131, 1, 0, 0, 0, 0, 0, 8, 71, 3, 0, 0, 0, 0, 0, 16, 206, 6, 0, 0, 0, 0, 0, 32, 156, 13, 0, 0, 0, 0, 0, 64, 56, 11, 0, 0, 0, 0, 0, 128, 48, 6};
// _ZZ14unified_kernelE10adj_matrix has been demoted
// _ZZ14unified_kernelE13result_matrix has been demoted

.visible .entry unified_kernel(
	.param .u64 unified_kernel_param_0,
	.param .u64 unified_kernel_param_1,
	.param .u64 unified_kernel_param_2,
	.param .u64 unified_kernel_param_3,
	.param .u64 unified_kernel_param_4,
	.param .u64 unified_kernel_param_5
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<23>;
	.reg .b32 	%r<43>;
	.reg .b64 	%rd<325>;
	// demoted variable
	.shared .align 8 .b8 _ZZ14unified_kernelE10adj_matrix[304];
	// demoted variable
	.shared .align 8 .b8 _ZZ14unified_kernelE13result_matrix[304];

	ld.param.u64 	%rd21, [unified_kernel_param_0];
	ld.param.u64 	%rd22, [unified_kernel_param_1];
	ld.param.u64 	%rd17, [unified_kernel_param_2];
	ld.param.u64 	%rd18, [unified_kernel_param_3];
	ld.param.u64 	%rd19, [unified_kernel_param_4];
	ld.param.u64 	%rd20, [unified_kernel_param_5];
	mov.u32 	%r5, %ctaid.x;
	cvt.u64.u32 	%rd1, %r5;
	mov.u32 	%r6, %tid.x;
	cvt.u64.u32 	%rd2, %r6;
	shl.b32 	%r7, %r6, 3;
	mov.u32 	%r8, _ZZ14unified_kernelE10adj_matrix;
	add.s32 	%r1, %r8, %r7;
	mov.u64 	%rd23, 0;
	st.shared.u64 	[%r1], %rd23;
	mov.u32 	%r9, _ZZ14unified_kernelE13result_matrix;
	add.s32 	%r2, %r9, %r7;
	st.shared.u64 	[%r2], %rd23;
	mul.wide.u32 	%rd24, %r5, 3;
	cvta.to.global.u64 	%rd25, %rd22;
	add.s64 	%rd26, %rd25, %rd24;
	ld.global.u8 	%rs1, [%rd26+1];
	ld.global.u8 	%rs2, [%rd26+2];
	setp.eq.s16 	%p1, %rs2, 100;
	cvta.to.global.u64 	%rd27, %rd21;
	ld.global.u64 	%rd3, [%rd27];
	ld.global.u8 	%rs3, [%rd26];
	cvt.u64.u16 	%rd28, %rs3;
	and.b64  	%rd4, %rd28, 255;
	@%p1 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;

$L__BB0_2:
	cvt.u32.u64 	%r23, %rd4;
	mov.u64 	%rd84, 1;
	shl.b64 	%rd85, %rd84, %r23;
	cvt.u32.u16 	%r24, %rs1;
	and.b32  	%r25, %r24, 255;
	shl.b64 	%rd86, %rd84, %r25;
	or.b64  	%rd87, %rd86, %rd85;
	xor.b64  	%rd88, %rd87, %rd3;
	mov.u64 	%rd89, -1;
	shl.b64 	%rd90, %rd89, %r23;
	not.b64 	%rd91, %rd90;
	and.b64  	%rd92, %rd91, %rd3;
	and.b64  	%rd93, %rd92, 274877906943;
	popc.b64 	%r26, %rd93;
	cvt.u64.u32 	%rd94, %r26;
	shl.b64 	%rd95, %rd94, 1;
	add.s64 	%rd96, %rd95, 38;
	cvt.u32.u64 	%r27, %rd96;
	shr.u64 	%rd97, %rd3, %r27;
	and.b64  	%rd98, %rd97, 3;
	cvt.u32.u64 	%r28, %rd95;
	mov.u64 	%rd99, 824633720832;
	shl.b64 	%rd100, %rd99, %r28;
	not.b64 	%rd101, %rd100;
	and.b64  	%rd102, %rd88, %rd101;
	mov.u64 	%rd103, -1099511627776;
	shl.b64 	%rd104, %rd103, %r28;
	and.b64  	%rd105, %rd102, %rd104;
	shr.u64 	%rd106, %rd105, 2;
	not.b64 	%rd107, %rd104;
	and.b64  	%rd108, %rd102, %rd107;
	or.b64  	%rd109, %rd106, %rd108;
	shl.b64 	%rd110, %rd89, %r25;
	not.b64 	%rd111, %rd110;
	and.b64  	%rd112, %rd3, %rd111;
	and.b64  	%rd113, %rd112, 274877906943;
	popc.b64 	%r29, %rd113;
	cvt.u64.u32 	%rd114, %r29;
	setp.lt.u16 	%p2, %rs3, %rs1;
	selp.b64 	%rd115, -1, 0, %p2;
	add.s64 	%rd116, %rd114, %rd115;
	shl.b64 	%rd117, %rd116, 1;
	add.s64 	%rd118, %rd117, 38;
	cvt.u32.u64 	%r30, %rd118;
	and.b32  	%r31, %r30, 254;
	shl.b64 	%rd119, %rd89, %r31;
	and.b64  	%rd120, %rd109, %rd119;
	shl.b64 	%rd121, %rd120, 2;
	not.b64 	%rd122, %rd119;
	and.b64  	%rd123, %rd109, %rd122;
	shl.b64 	%rd124, %rd98, %r31;
	or.b64  	%rd125, %rd123, %rd124;
	or.b64  	%rd323, %rd125, %rd121;
	bra.uni 	$L__BB0_3;

$L__BB0_1:
	cvt.u32.u64 	%r10, %rd4;
	mov.u64 	%rd29, -1;
	shl.b64 	%rd30, %rd29, %r10;
	not.b64 	%rd31, %rd30;
	and.b64  	%rd32, %rd31, %rd3;
	and.b64  	%rd33, %rd32, 274877906943;
	popc.b64 	%r11, %rd33;
	cvt.u64.u32 	%rd34, %r11;
	shl.b64 	%rd35, %rd34, 1;
	mov.u64 	%rd36, 1;
	add.s64 	%rd37, %rd35, 38;
	cvt.u32.u64 	%r12, %rd37;
	shr.u64 	%rd38, %rd3, %r12;
	and.b64  	%rd39, %rd38, 3;
	cvt.u32.u64 	%r13, %rd35;
	mov.u64 	%rd40, 824633720832;
	shl.b64 	%rd41, %rd40, %r13;
	not.b64 	%rd42, %rd41;
	and.b64  	%rd43, %rd3, %rd42;
	mov.u64 	%rd44, -1099511627776;
	shl.b64 	%rd45, %rd44, %r13;
	and.b64  	%rd46, %rd43, %rd45;
	shr.u64 	%rd47, %rd46, 2;
	not.b64 	%rd48, %rd45;
	and.b64  	%rd49, %rd43, %rd48;
	or.b64  	%rd50, %rd47, %rd49;
	shl.b64 	%rd51, %rd36, %r10;
	xor.b64  	%rd52, %rd50, %rd51;
	cvt.u32.u16 	%r14, %rs1;
	and.b32  	%r15, %r14, 255;
	shl.b64 	%rd53, %rd29, %r15;
	not.b64 	%rd54, %rd53;
	and.b64  	%rd55, %rd54, %rd52;
	and.b64  	%rd56, %rd55, 274877906943;
	popc.b64 	%r16, %rd56;
	cvt.u64.u32 	%rd57, %r16;
	shl.b64 	%rd58, %rd57, 1;
	add.s64 	%rd59, %rd58, 38;
	cvt.u32.u64 	%r17, %rd59;
	shr.u64 	%rd60, %rd52, %r17;
	and.b64  	%rd61, %rd60, 3;
	cvt.u32.u64 	%r18, %rd58;
	shl.b64 	%rd62, %rd40, %r18;
	not.b64 	%rd63, %rd62;
	and.b64  	%rd64, %rd52, %rd63;
	shl.b64 	%rd65, %rd39, %r17;
	or.b64  	%rd66, %rd64, %rd65;
	cvt.u32.u16 	%r19, %rs2;
	shl.b64 	%rd67, %rd29, %r19;
	not.b64 	%rd68, %rd67;
	and.b64  	%rd69, %rd68, %rd66;
	and.b64  	%rd70, %rd69, 274877906943;
	popc.b64 	%r20, %rd70;
	cvt.u64.u32 	%rd71, %r20;
	shl.b64 	%rd72, %rd71, 1;
	add.s64 	%rd73, %rd72, 38;
	cvt.u32.u64 	%r21, %rd72;
	mov.u64 	%rd74, -274877906944;
	shl.b64 	%rd75, %rd74, %r21;
	and.b64  	%rd76, %rd75, %rd66;
	shl.b64 	%rd77, %rd76, 2;
	not.b64 	%rd78, %rd75;
	and.b64  	%rd79, %rd66, %rd78;
	cvt.u32.u64 	%r22, %rd73;
	shl.b64 	%rd80, %rd61, %r22;
	or.b64  	%rd81, %rd80, %rd79;
	or.b64  	%rd82, %rd81, %rd77;
	shl.b64 	%rd83, %rd36, %r19;
	xor.b64  	%rd323, %rd82, %rd83;

$L__BB0_3:
	and.b64  	%rd8, %rd323, 274877906943;
	cvt.u32.u64 	%r32, %rd2;
	and.b32  	%r33, %r32, 255;
	and.b64  	%rd9, %rd2, 255;
	mov.u64 	%rd126, 1;
	shl.b64 	%rd127, %rd126, %r33;
	and.b64  	%rd128, %rd323, %rd127;
	setp.eq.s64 	%p3, %rd128, 0;
	mov.u16 	%rs22, 0;
	@%p3 bra 	$L__BB0_5;

	cvt.u32.u64 	%r34, %rd9;
	mov.u64 	%rd129, -1;
	shl.b64 	%rd130, %rd129, %r34;
	not.b64 	%rd131, %rd130;
	and.b64  	%rd132, %rd131, %rd323;
	and.b64  	%rd133, %rd132, 274877906943;
	popc.b64 	%r35, %rd133;
	cvt.u64.u32 	%rd134, %r35;
	shl.b64 	%rd135, %rd134, 1;
	add.s64 	%rd136, %rd135, 38;
	cvt.u32.u64 	%r36, %rd136;
	shr.u64 	%rd137, %rd323, %r36;
	cvt.u16.u64 	%rs9, %rd137;
	and.b16  	%rs22, %rs9, 3;

$L__BB0_5:
	setp.gt.u32 	%p4, %r32, 35;
	setp.eq.s16 	%p5, %rs22, 0;
	or.pred  	%p6, %p4, %p5;
	@%p6 bra 	$L__BB0_12;

	setp.eq.s16 	%p7, %rs22, 1;
	@%p7 bra 	$L__BB0_10;
	bra.uni 	$L__BB0_7;

$L__BB0_10:
	cvta.to.global.u64 	%rd163, %rd18;
	shl.b64 	%rd164, %rd2, 3;
	add.s64 	%rd324, %rd163, %rd164;
	bra.uni 	$L__BB0_11;

$L__BB0_7:
	setp.eq.s16 	%p8, %rs22, 2;
	shl.b64 	%rd138, %rd2, 3;
	mov.u64 	%rd139, ALL_INTERCEPTS;
	add.s64 	%rd10, %rd139, %rd138;
	@%p8 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_8;

$L__BB0_9:
	ld.const.u64 	%rd150, [%rd10];
	and.b64  	%rd151, %rd150, %rd8;
	mul.hi.u64 	%rd152, %rd151, 1908283869694091547;
	sub.s64 	%rd153, %rd151, %rd152;
	shr.u64 	%rd154, %rd153, 1;
	add.s64 	%rd155, %rd154, %rd152;
	shr.u64 	%rd156, %rd155, 4;
	mul.lo.s64 	%rd157, %rd156, 29;
	sub.s64 	%rd158, %rd151, %rd157;
	mul.lo.s64 	%rd159, %rd2, 29;
	add.s64 	%rd160, %rd158, %rd159;
	cvta.to.global.u64 	%rd161, %rd19;
	shl.b64 	%rd162, %rd160, 3;
	add.s64 	%rd324, %rd161, %rd162;
	bra.uni 	$L__BB0_11;

$L__BB0_8:
	ld.const.u64 	%rd140, [%rd10+288];
	and.b64  	%rd141, %rd140, %rd8;
	mul.hi.u64 	%rd142, %rd141, 6864528366122860309;
	shr.u64 	%rd143, %rd142, 12;
	mul.lo.s64 	%rd144, %rd143, 11007;
	sub.s64 	%rd145, %rd141, %rd144;
	mul.lo.s64 	%rd146, %rd2, 11007;
	add.s64 	%rd147, %rd145, %rd146;
	cvta.to.global.u64 	%rd148, %rd20;
	shl.b64 	%rd149, %rd147, 3;
	add.s64 	%rd324, %rd148, %rd149;

$L__BB0_11:
	or.b64  	%rd165, %rd8, 206158430208;
	ld.global.u64 	%rd166, [%rd324];
	and.b64  	%rd167, %rd166, %rd165;
	st.shared.u64 	[%r1], %rd167;
	st.shared.u64 	[%r2], %rd167;

$L__BB0_12:
	bar.sync 	0;
	cvta.to.global.u64 	%rd15, %rd17;
	mov.u32 	%r42, 8;

$L__BB0_13:
	ld.shared.u64 	%rd168, [%r2];
	and.b64  	%rd169, %rd168, 1;
	ld.shared.u64 	%rd170, [_ZZ14unified_kernelE10adj_matrix];
	mul.lo.s64 	%rd171, %rd169, %rd170;
	bfe.u64 	%rd172, %rd168, 1, 1;
	ld.shared.u64 	%rd173, [_ZZ14unified_kernelE10adj_matrix+8];
	mul.lo.s64 	%rd174, %rd172, %rd173;
	or.b64  	%rd175, %rd174, %rd171;
	bfe.u64 	%rd176, %rd168, 2, 1;
	ld.shared.u64 	%rd177, [_ZZ14unified_kernelE10adj_matrix+16];
	mul.lo.s64 	%rd178, %rd176, %rd177;
	or.b64  	%rd179, %rd178, %rd175;
	bfe.u64 	%rd180, %rd168, 3, 1;
	ld.shared.u64 	%rd181, [_ZZ14unified_kernelE10adj_matrix+24];
	mul.lo.s64 	%rd182, %rd180, %rd181;
	or.b64  	%rd183, %rd182, %rd179;
	bfe.u64 	%rd184, %rd168, 4, 1;
	ld.shared.u64 	%rd185, [_ZZ14unified_kernelE10adj_matrix+32];
	mul.lo.s64 	%rd186, %rd184, %rd185;
	or.b64  	%rd187, %rd186, %rd183;
	bfe.u64 	%rd188, %rd168, 5, 1;
	ld.shared.u64 	%rd189, [_ZZ14unified_kernelE10adj_matrix+40];
	mul.lo.s64 	%rd190, %rd188, %rd189;
	or.b64  	%rd191, %rd190, %rd187;
	bfe.u64 	%rd192, %rd168, 6, 1;
	ld.shared.u64 	%rd193, [_ZZ14unified_kernelE10adj_matrix+48];
	mul.lo.s64 	%rd194, %rd192, %rd193;
	or.b64  	%rd195, %rd194, %rd191;
	bfe.u64 	%rd196, %rd168, 7, 1;
	ld.shared.u64 	%rd197, [_ZZ14unified_kernelE10adj_matrix+56];
	mul.lo.s64 	%rd198, %rd196, %rd197;
	or.b64  	%rd199, %rd198, %rd195;
	bfe.u64 	%rd200, %rd168, 8, 1;
	ld.shared.u64 	%rd201, [_ZZ14unified_kernelE10adj_matrix+64];
	mul.lo.s64 	%rd202, %rd200, %rd201;
	or.b64  	%rd203, %rd202, %rd199;
	bfe.u64 	%rd204, %rd168, 9, 1;
	ld.shared.u64 	%rd205, [_ZZ14unified_kernelE10adj_matrix+72];
	mul.lo.s64 	%rd206, %rd204, %rd205;
	or.b64  	%rd207, %rd206, %rd203;
	bfe.u64 	%rd208, %rd168, 10, 1;
	ld.shared.u64 	%rd209, [_ZZ14unified_kernelE10adj_matrix+80];
	mul.lo.s64 	%rd210, %rd208, %rd209;
	or.b64  	%rd211, %rd210, %rd207;
	bfe.u64 	%rd212, %rd168, 11, 1;
	ld.shared.u64 	%rd213, [_ZZ14unified_kernelE10adj_matrix+88];
	mul.lo.s64 	%rd214, %rd212, %rd213;
	or.b64  	%rd215, %rd214, %rd211;
	bfe.u64 	%rd216, %rd168, 12, 1;
	ld.shared.u64 	%rd217, [_ZZ14unified_kernelE10adj_matrix+96];
	mul.lo.s64 	%rd218, %rd216, %rd217;
	or.b64  	%rd219, %rd218, %rd215;
	bfe.u64 	%rd220, %rd168, 13, 1;
	ld.shared.u64 	%rd221, [_ZZ14unified_kernelE10adj_matrix+104];
	mul.lo.s64 	%rd222, %rd220, %rd221;
	or.b64  	%rd223, %rd222, %rd219;
	bfe.u64 	%rd224, %rd168, 14, 1;
	ld.shared.u64 	%rd225, [_ZZ14unified_kernelE10adj_matrix+112];
	mul.lo.s64 	%rd226, %rd224, %rd225;
	or.b64  	%rd227, %rd226, %rd223;
	bfe.u64 	%rd228, %rd168, 15, 1;
	ld.shared.u64 	%rd229, [_ZZ14unified_kernelE10adj_matrix+120];
	mul.lo.s64 	%rd230, %rd228, %rd229;
	or.b64  	%rd231, %rd230, %rd227;
	bfe.u64 	%rd232, %rd168, 16, 1;
	ld.shared.u64 	%rd233, [_ZZ14unified_kernelE10adj_matrix+128];
	mul.lo.s64 	%rd234, %rd232, %rd233;
	or.b64  	%rd235, %rd234, %rd231;
	bfe.u64 	%rd236, %rd168, 17, 1;
	ld.shared.u64 	%rd237, [_ZZ14unified_kernelE10adj_matrix+136];
	mul.lo.s64 	%rd238, %rd236, %rd237;
	or.b64  	%rd239, %rd238, %rd235;
	bfe.u64 	%rd240, %rd168, 18, 1;
	ld.shared.u64 	%rd241, [_ZZ14unified_kernelE10adj_matrix+144];
	mul.lo.s64 	%rd242, %rd240, %rd241;
	or.b64  	%rd243, %rd242, %rd239;
	bfe.u64 	%rd244, %rd168, 19, 1;
	ld.shared.u64 	%rd245, [_ZZ14unified_kernelE10adj_matrix+152];
	mul.lo.s64 	%rd246, %rd244, %rd245;
	or.b64  	%rd247, %rd246, %rd243;
	bfe.u64 	%rd248, %rd168, 20, 1;
	ld.shared.u64 	%rd249, [_ZZ14unified_kernelE10adj_matrix+160];
	mul.lo.s64 	%rd250, %rd248, %rd249;
	or.b64  	%rd251, %rd250, %rd247;
	bfe.u64 	%rd252, %rd168, 21, 1;
	ld.shared.u64 	%rd253, [_ZZ14unified_kernelE10adj_matrix+168];
	mul.lo.s64 	%rd254, %rd252, %rd253;
	or.b64  	%rd255, %rd254, %rd251;
	bfe.u64 	%rd256, %rd168, 22, 1;
	ld.shared.u64 	%rd257, [_ZZ14unified_kernelE10adj_matrix+176];
	mul.lo.s64 	%rd258, %rd256, %rd257;
	or.b64  	%rd259, %rd258, %rd255;
	bfe.u64 	%rd260, %rd168, 23, 1;
	ld.shared.u64 	%rd261, [_ZZ14unified_kernelE10adj_matrix+184];
	mul.lo.s64 	%rd262, %rd260, %rd261;
	or.b64  	%rd263, %rd262, %rd259;
	bfe.u64 	%rd264, %rd168, 24, 1;
	ld.shared.u64 	%rd265, [_ZZ14unified_kernelE10adj_matrix+192];
	mul.lo.s64 	%rd266, %rd264, %rd265;
	or.b64  	%rd267, %rd266, %rd263;
	bfe.u64 	%rd268, %rd168, 25, 1;
	ld.shared.u64 	%rd269, [_ZZ14unified_kernelE10adj_matrix+200];
	mul.lo.s64 	%rd270, %rd268, %rd269;
	or.b64  	%rd271, %rd270, %rd267;
	bfe.u64 	%rd272, %rd168, 26, 1;
	ld.shared.u64 	%rd273, [_ZZ14unified_kernelE10adj_matrix+208];
	mul.lo.s64 	%rd274, %rd272, %rd273;
	or.b64  	%rd275, %rd274, %rd271;
	bfe.u64 	%rd276, %rd168, 27, 1;
	ld.shared.u64 	%rd277, [_ZZ14unified_kernelE10adj_matrix+216];
	mul.lo.s64 	%rd278, %rd276, %rd277;
	or.b64  	%rd279, %rd278, %rd275;
	bfe.u64 	%rd280, %rd168, 28, 1;
	ld.shared.u64 	%rd281, [_ZZ14unified_kernelE10adj_matrix+224];
	mul.lo.s64 	%rd282, %rd280, %rd281;
	or.b64  	%rd283, %rd282, %rd279;
	bfe.u64 	%rd284, %rd168, 29, 1;
	ld.shared.u64 	%rd285, [_ZZ14unified_kernelE10adj_matrix+232];
	mul.lo.s64 	%rd286, %rd284, %rd285;
	or.b64  	%rd287, %rd286, %rd283;
	bfe.u64 	%rd288, %rd168, 30, 1;
	ld.shared.u64 	%rd289, [_ZZ14unified_kernelE10adj_matrix+240];
	mul.lo.s64 	%rd290, %rd288, %rd289;
	or.b64  	%rd291, %rd290, %rd287;
	bfe.u64 	%rd292, %rd168, 31, 1;
	ld.shared.u64 	%rd293, [_ZZ14unified_kernelE10adj_matrix+248];
	mul.lo.s64 	%rd294, %rd292, %rd293;
	or.b64  	%rd295, %rd294, %rd291;
	shr.u64 	%rd296, %rd168, 32;
	and.b64  	%rd297, %rd296, 1;
	ld.shared.u64 	%rd298, [_ZZ14unified_kernelE10adj_matrix+256];
	mul.lo.s64 	%rd299, %rd297, %rd298;
	or.b64  	%rd300, %rd299, %rd295;
	bfe.u64 	%rd301, %rd168, 33, 1;
	ld.shared.u64 	%rd302, [_ZZ14unified_kernelE10adj_matrix+264];
	mul.lo.s64 	%rd303, %rd301, %rd302;
	or.b64  	%rd304, %rd303, %rd300;
	bfe.u64 	%rd305, %rd168, 34, 1;
	ld.shared.u64 	%rd306, [_ZZ14unified_kernelE10adj_matrix+272];
	mul.lo.s64 	%rd307, %rd305, %rd306;
	or.b64  	%rd308, %rd307, %rd304;
	bfe.u64 	%rd309, %rd168, 35, 1;
	ld.shared.u64 	%rd310, [_ZZ14unified_kernelE10adj_matrix+280];
	mul.lo.s64 	%rd311, %rd309, %rd310;
	or.b64  	%rd312, %rd311, %rd308;
	bfe.u64 	%rd313, %rd168, 36, 1;
	ld.shared.u64 	%rd314, [_ZZ14unified_kernelE10adj_matrix+288];
	mul.lo.s64 	%rd315, %rd313, %rd314;
	or.b64  	%rd316, %rd315, %rd312;
	bfe.u64 	%rd317, %rd168, 37, 1;
	ld.shared.u64 	%rd318, [_ZZ14unified_kernelE10adj_matrix+296];
	mul.lo.s64 	%rd319, %rd317, %rd318;
	or.b64  	%rd320, %rd319, %rd316;
	or.b64  	%rd321, %rd168, %rd320;
	st.shared.u64 	[%r2], %rd321;
	bar.sync 	0;
	add.s32 	%r42, %r42, -1;
	setp.ne.s32 	%p9, %r42, 0;
	@%p9 bra 	$L__BB0_13;

	setp.ne.s32 	%p10, %r32, 0;
	@%p10 bra 	$L__BB0_23;

	ld.shared.u8 	%rs10, [_ZZ14unified_kernelE13result_matrix+244];
	and.b16  	%rs11, %rs10, 16;
	setp.ne.s16 	%p11, %rs11, 0;
	shl.b64 	%rd322, %rd1, 2;
	add.s64 	%rd16, %rd15, %rd322;
	@%p11 bra 	$L__BB0_21;

	ld.shared.u8 	%rs12, [_ZZ14unified_kernelE13result_matrix+252];
	and.b16  	%rs13, %rs12, 16;
	setp.ne.s16 	%p12, %rs13, 0;
	@%p12 bra 	$L__BB0_21;

	ld.shared.u8 	%rs14, [_ZZ14unified_kernelE13result_matrix+260];
	and.b16  	%rs15, %rs14, 16;
	setp.ne.s16 	%p13, %rs15, 0;
	@%p13 bra 	$L__BB0_21;

	ld.shared.u8 	%rs16, [_ZZ14unified_kernelE13result_matrix+268];
	and.b16  	%rs17, %rs16, 16;
	setp.ne.s16 	%p14, %rs17, 0;
	@%p14 bra 	$L__BB0_21;

	ld.shared.u8 	%rs18, [_ZZ14unified_kernelE13result_matrix+276];
	and.b16  	%rs19, %rs18, 16;
	setp.ne.s16 	%p15, %rs19, 0;
	@%p15 bra 	$L__BB0_21;

	ld.shared.u8 	%rs20, [_ZZ14unified_kernelE13result_matrix+284];
	and.b16  	%rs21, %rs20, 16;
	setp.eq.s16 	%p16, %rs21, 0;
	@%p16 bra 	$L__BB0_22;
	bra.uni 	$L__BB0_21;

$L__BB0_22:
	mov.u32 	%r41, 0;
	st.global.u32 	[%rd16], %r41;
	bra.uni 	$L__BB0_23;

$L__BB0_21:
	mov.u32 	%r40, 1065353216;
	st.global.u32 	[%rd16], %r40;

$L__BB0_23:
	ret;

}

